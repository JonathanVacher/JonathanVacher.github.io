<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://jonathanvacher.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://jonathanvacher.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2020-12-09T12:20:38+01:00</updated><id>https://jonathanvacher.github.io/feed.xml</id><title type="html">Jonathan Vacher</title><subtitle>Postdoc @ Albert Einstein, New-York
</subtitle><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><entry><title type="html">Texture Interpolation for Probing Visual Perception</title><link href="https://jonathanvacher.github.io/publications/2020-12-09-Neurips-paper/" rel="alternate" type="text/html" title="Texture Interpolation for Probing Visual Perception" /><published>2020-12-09T00:00:00+01:00</published><updated>2020-12-09T00:00:00+01:00</updated><id>https://jonathanvacher.github.io/publications/Neurips-paper</id><content type="html" xml:base="https://jonathanvacher.github.io/publications/2020-12-09-Neurips-paper/">&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://neurips.cc/virtual/2020/protected/session_oral_21095.html&quot;&gt;Live stream&lt;/a&gt; 12/9/20 at 7:10 PM PST&lt;/td&gt;
      &lt;td&gt;Q&amp;amp;A session 7:40 PM PST&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://nips.cc/virtual/2020/protected/poster_fba9d88164f3e2d9109ee770223212a0.html&quot;&gt;Poster&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://neurips2020.rocket.chat/channel/texture-interpolation-for-probing-visual-perception-99&quot;&gt;Rocket Chat&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://neurips.gather.town/app/qJ1RizBHxNrKQl6d/posterRoomD1?spawnx=33&amp;amp;spawny=48&amp;amp;map=neuripscustom-entrance&quot;&gt;GatherTown&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;We use the Optimal Transport framework to interpolate between textures and use these textures in a perceptual task. We also recorded the macaque primary and mid-level visual cortex.&lt;/p&gt;

&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-vacher2020texture&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column1 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 0px;
}

.column2 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 8px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}

.btn{
  width: 90px;
  height: 25px;
  background: url('https://jonathanvacher.github.io/assets/icons/BibTeX_logo.png') no-repeat center;
  background-color: #e7e7e7;
  border-radius: 8px;
}

.inline{
  display: inline-block;
}
&lt;/style&gt;

&lt;span id=&quot;post2-vacher2020texture&quot;&gt;Vacher, J., Davila, A., Kohn, A. &amp;amp; Coen-Cagli, R. Texture Interpolation for Probing Visual Perception. &lt;i&gt;Advances in Neural Information Processing Systems (Spotlight – top 5%)&lt;/i&gt; (2020).&lt;/span&gt;
&lt;div class=&quot;inline&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;column1&quot;&gt;
        &lt;button class=&quot;btn&quot; onclick=&quot;myFunctionvacher2020texture()&quot;&gt;&lt;/button&gt; 
        &lt;/div&gt;
        &lt;div class=&quot;column2&quot;&gt;
        &lt;a href=&quot;/pdf/vacher2020texture.pdf&quot;&gt;&lt;img src=&quot;https://jonathanvacher.github.io/assets/icons/pdf_icon.png&quot; float=&quot;right&quot; /&gt;&lt;/a&gt;     		
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;vacher2020texture-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;vacher2020texture-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{vacher2020texture,
  title = {Texture Interpolation for Probing Visual Perception},
  author = {Vacher, Jonathan and Davila, Aida and Kohn, Adam and Coen-Cagli, Ruben},
  journal = {Advances in Neural Information Processing Systems (Spotlight -- top 5\%)},
  year = {2020}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;script&gt;
function myFunctionvacher2020texture() {
  var x = document.getElementById(&quot;vacher2020texture-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
/*
 &lt;div class=&quot;column0&quot;&gt;
  	&lt;/div&gt; */
&lt;/script&gt;
&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-vacher2020texture&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;Texture synthesis models are important to understand visual processing. In particu-lar, statistical approaches based on neurally relevant features have been instrumentalto understanding aspects of visual perception and of neural coding.  New deeplearning-based approaches further improve the quality of synthetic textures. Yet, itis still unclear why deep texture synthesis performs so well, and applications ofthis new framework to probe visual perception are scarce. Here, we show that dis-tributions of deep convolutional neural network (CNN) activations of a texture arewell described by elliptical distributions and therefore, following optimal transporttheory, constraining their mean and covariance is sufficient to generate new texturesamples. Then, we propose the natural geodesics (i.e.the shortest path between twopoints) arising with the optimal transport metric to interpolate between arbitrarytextures. The comparison to alternative interpolation methods suggests that oursmatches more closely the geometry of texture perception, and is better suited tostudy its statistical nature. We demonstrate our method by measuring the perceptualscale associated to the interpolation parameter in human observers, and the neuralsensitivity of different areas of visual cortex in macaque monkeys.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><category term="publications" /><summary type="html">Live stream 12/9/20 at 7:10 PM PST Q&amp;amp;A session 7:40 PM PST Poster Rocket Chat GatherTown</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/neurips-2020.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/neurips-2020.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">New postdoc position</title><link href="https://jonathanvacher.github.io/milestones/2020-09-01-new-postdoc-position/" rel="alternate" type="text/html" title="New postdoc position" /><published>2020-09-01T00:00:00+02:00</published><updated>2020-09-01T00:00:00+02:00</updated><id>https://jonathanvacher.github.io/milestones/new-postdoc-position</id><content type="html" xml:base="https://jonathanvacher.github.io/milestones/2020-09-01-new-postdoc-position/">&lt;p&gt;The work is in the continuation of my previous Postdoc. And I will be surpervised by Pascal Mamassian and Ruben Coen-Cagli (AECOM, NYC).&lt;/p&gt;

&lt;p&gt;We work on natural image segmentation. Our goal is to develop a neurally plausible model of image segmentation and to use it to conduct well control psychometric experiments with artificial and natural images.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><category term="milestones" /><summary type="html">The work is in the continuation of my previous Postdoc. And I will be surpervised by Pascal Mamassian and Ruben Coen-Cagli (AECOM, NYC).</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/ens.jpg" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/ens.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">VSS Poster</title><link href="https://jonathanvacher.github.io/conferences/2020-06-21-poster-vss/" rel="alternate" type="text/html" title="VSS Poster" /><published>2020-06-21T00:00:00+02:00</published><updated>2020-06-21T00:00:00+02:00</updated><id>https://jonathanvacher.github.io/conferences/poster-vss</id><content type="html" xml:base="https://jonathanvacher.github.io/conferences/2020-06-21-poster-vss/">&lt;p&gt;Visual segmentation is a core function of biological vision, key to adaptive behavior in complex environments. Early models inspired by the feedforward processing in the visual system described texture-based human segmentation as a comparison of the summary statistics of low-level image features across space. Here we consider the alternative view that, due to image ambiguity and sensory noise, perceptual segmentation requires probabilistic inference.&lt;/p&gt;

&lt;p&gt;To test this hypothesis, we develop a novel paradigm to measure perceptual segmentation maps and their variability. We use composite textures: each segment is characterized by a different distribution of oriented features. Participants briefly view an image followed by two spatial cues and report whether the cued locations belong to the same segment. We repeat the sequence with different locations and reconstruct the full segmentation map from the binary choices, solving a system of equations. In a second set of experiments, we manipulate uncertainty by controlling the overlap between feature distributions and smoothing the texture boundary and measure texture discrimination performance.&lt;/p&gt;

&lt;p&gt;We find that segmentation maps are similar across observers but variable: perceptual variability correlates with intrinsic image uncertainty, and both are higher near segment boundaries. We then test the inference model that consists in assigning pixels to segments by evaluating which distribution explains best the observed features. Quantitative model comparison shows that perceptual variability reflects image uncertainty beyond sensory noise and that human segmentation is better explained by optimal probabilistic inference than by comparing summary statistics. Lastly, we find an interaction between the effects of contour uncertainty and feature distribution overlap.&lt;/p&gt;

&lt;p&gt;These results support the probabilistic inference hypothesis and suggest extending the model with contour specific components. Our work provides a normative explanation of human perceptual segmentation as probabilistic inference and demonstrates a novel framework to study perceptual segmentation, which could be extended to natural images.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><category term="conferences" /><summary type="html">Visual segmentation is a core function of biological vision, key to adaptive behavior in complex environments. Early models inspired by the feedforward processing in the visual system described texture-based human segmentation as a comparison of the summary statistics of low-level image features across space. Here we consider the alternative view that, due to image ambiguity and sensory noise, perceptual segmentation requires probabilistic inference.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/poster-vss-2020.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/poster-vss-2020.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Cosyne Poster</title><link href="https://jonathanvacher.github.io/conferences/2020-02-29-poster-cosyne/" rel="alternate" type="text/html" title="Cosyne Poster" /><published>2020-02-29T00:00:00+01:00</published><updated>2020-02-29T00:00:00+01:00</updated><id>https://jonathanvacher.github.io/conferences/poster-cosyne</id><content type="html" xml:base="https://jonathanvacher.github.io/conferences/2020-02-29-poster-cosyne/">&lt;p&gt;Visual segmentation is a core function of biological vision, key to adaptive behavior in complex environments. Foundational work identified Gestalt principles of segmentation, e.g. grouping by similarity, proximity and good continuation, and revealed that visual cortical neurons are sensitive to those cues. Early models inspired by the feedforward cortical architecture described texture-based human segmentation as the process of comparing the summary statistics of low-level visual features across space. Indeed the summary statistics representation is the most prominent model of naturalistic texture perception, yet it has been challenged precisely because it does not fully capture the influence of segmentation.&lt;/p&gt;

&lt;p&gt;Here we consider the alternative view that, due to image ambiguity and sensory noise, perceptual segmentation requires probabilistic inference. This view is consistent with reports that humans combine multiple segmentation cues near-optimally in artificial displays, and that Gestalt laws reflect optimization to natural image statistics. The probabilistic approach is also widespread in computer vision algorithms for unsupervised segmentation, but has not been used to model perceptual segmentation. We present new experiments that for the first time measure perceptual segmentation maps and their variability, allowing us to test the probabilistic inference hypothesis, and compare it quantitatively to summary statistics models.&lt;/p&gt;

&lt;p&gt;We use composite textures, with segments characterized by different statistical relations between features. Optimal probabilistic inference assigns pixels to segments by evaluating which of those relations better explains the observed features (generative model), as opposed to comparing summary statistics at different locations (feature discrimination). We find the generative model best captures our data, and perceptual variability reflects image uncertainty beyond sensory noise. We also demonstrate the approach on natural images, which will allow testing more sophisticated segmentation algorithms. Our results provide a normative explanation of human perceptual segmentation as probabilistic inference, and demonstrate a novel framework to study perceptual segmentation of natural images.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><category term="conferences" /><summary type="html">Visual segmentation is a core function of biological vision, key to adaptive behavior in complex environments. Foundational work identified Gestalt principles of segmentation, e.g. grouping by similarity, proximity and good continuation, and revealed that visual cortical neurons are sensitive to those cues. Early models inspired by the feedforward cortical architecture described texture-based human segmentation as the process of comparing the summary statistics of low-level visual features across space. Indeed the summary statistics representation is the most prominent model of naturalistic texture perception, yet it has been challenged precisely because it does not fully capture the influence of segmentation.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/poster-cosyne-2020.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/poster-cosyne-2020.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Probabilistic reachability and control synthesis for stochastic switched systems using the tamed Euler method.</title><link href="https://jonathanvacher.github.io/publications/2020-01-14-New-paper-in-NAHS/" rel="alternate" type="text/html" title="Probabilistic reachability and control synthesis for stochastic switched systems using the tamed Euler method." /><published>2020-01-14T00:00:00+01:00</published><updated>2020-01-14T00:00:00+01:00</updated><id>https://jonathanvacher.github.io/publications/New-paper-in-NAHS</id><content type="html" xml:base="https://jonathanvacher.github.io/publications/2020-01-14-New-paper-in-NAHS/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;We combined our knowledge to apply a direct symbolic control method to SDEs. We guarantee that solutions remain in a tube with high-proba!&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-lecoent2020probabilistic&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column1 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 0px;
}

.column2 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 8px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}

.btn{
  width: 90px;
  height: 25px;
  background: url('https://jonathanvacher.github.io/assets/icons/BibTeX_logo.png') no-repeat center;
  background-color: #e7e7e7;
  border-radius: 8px;
}

.inline{
  display: inline-block;
}
&lt;/style&gt;

&lt;span id=&quot;post2-lecoent2020probabilistic&quot;&gt;Le Coënt, A., Fribourg, L., Vacher, J. &amp;amp; Wisniewski, R. Probabilistic reachability and control synthesis for stochastic switched systems using the tamed Euler method. &lt;i&gt;Nonlinear Analysis: Hybrid Systems&lt;/i&gt; &lt;b&gt;36&lt;/b&gt;, 100860 (2020).&lt;/span&gt;
&lt;div class=&quot;inline&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;column1&quot;&gt;
        &lt;button class=&quot;btn&quot; onclick=&quot;myFunctionlecoent2020probabilistic()&quot;&gt;&lt;/button&gt; 
        &lt;/div&gt;
        &lt;div class=&quot;column2&quot;&gt;
        &lt;a href=&quot;/pdf/lecoent2020probabilistic.pdf&quot;&gt;&lt;img src=&quot;https://jonathanvacher.github.io/assets/icons/pdf_icon.png&quot; float=&quot;right&quot; /&gt;&lt;/a&gt;     		
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;lecoent2020probabilistic-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;lecoent2020probabilistic-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{lecoent2020probabilistic,
  title = {Probabilistic reachability and control synthesis for stochastic switched systems using the tamed Euler method},
  author = {Le Co\&quot;ent, Adrien and Fribourg, Laurent and Vacher, Jonathan and Wisniewski, Rafael},
  journal = {Nonlinear Analysis: Hybrid Systems},
  volume = {36},
  pages = {100860},
  year = {2020},
  publisher = {Elsevier},
  doi = {10.1016/j.nahs.2020.100860}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;script&gt;
function myFunctionlecoent2020probabilistic() {
  var x = document.getElementById(&quot;lecoent2020probabilistic-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
/*
 &lt;div class=&quot;column0&quot;&gt;
  	&lt;/div&gt; */
&lt;/script&gt;
&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-lecoent2020probabilistic&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;In this paper, we explain how, under the one-sided Lipschitz (OSL) hypothesis, one can find a mean square error bound for a variant of the Euler–Maruyama approximation method for stochastic switched systems. Subsequently, we explain how this bound can be used to control a stochastic switched system in order to make it reach a target zone with guaranteed minimum probability. The method is illustrated on several examples from the literature.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><category term="publications" /><summary type="html">Le Coënt, A., Fribourg, L., Vacher, J. &amp;amp; Wisniewski, R. Probabilistic reachability and control synthesis for stochastic switched systems using the tamed Euler method. Nonlinear Analysis: Hybrid Systems 36, 100860 (2020). @article{lecoent2020probabilistic, title = {Probabilistic reachability and control synthesis for stochastic switched systems using the tamed Euler method}, author = {Le Co\&quot;ent, Adrien and Fribourg, Laurent and Vacher, Jonathan and Wisniewski, Rafael}, journal = {Nonlinear Analysis: Hybrid Systems}, volume = {36}, pages = {100860}, year = {2020}, publisher = {Elsevier}, doi = {10.1016/j.nahs.2020.100860} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/nahs-2020.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/nahs-2020.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Auditory motion perception emerges from successive sound localizations integrated over time.</title><link href="https://jonathanvacher.github.io/publications/2019-11-11-New-paper-in-SciRep/" rel="alternate" type="text/html" title="Auditory motion perception emerges from successive sound localizations integrated over time." /><published>2019-11-11T00:00:00+01:00</published><updated>2019-11-11T00:00:00+01:00</updated><id>https://jonathanvacher.github.io/publications/New-paper-in-SciRep</id><content type="html" xml:base="https://jonathanvacher.github.io/publications/2019-11-11-New-paper-in-SciRep/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;We provide a connection between sound localization and sound motion perception through the upper limit (UL) speed of sound direction discrimination. We propose a spectral cue that explains both front-back confusion rates and the variation of the UL speed with the spectral content when accounting for a minimal integration time in the auditory cortex.&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-roggerone2019auditory&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column1 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 0px;
}

.column2 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 8px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}

.btn{
  width: 90px;
  height: 25px;
  background: url('https://jonathanvacher.github.io/assets/icons/BibTeX_logo.png') no-repeat center;
  background-color: #e7e7e7;
  border-radius: 8px;
}

.inline{
  display: inline-block;
}
&lt;/style&gt;

&lt;span id=&quot;post2-roggerone2019auditory&quot;&gt;Roggerone, V., Vacher, J., Tarlao, C. &amp;amp; Guastavino, C. Auditory motion perception emerges from successive sound localizations integrated over time. &lt;i&gt;Scientific Reports&lt;/i&gt; &lt;b&gt;9&lt;/b&gt;, 16437 (2019).&lt;/span&gt;
&lt;div class=&quot;inline&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;column1&quot;&gt;
        &lt;button class=&quot;btn&quot; onclick=&quot;myFunctionroggerone2019auditory()&quot;&gt;&lt;/button&gt; 
        &lt;/div&gt;
        &lt;div class=&quot;column2&quot;&gt;
        &lt;a href=&quot;/pdf/roggerone2019auditory.pdf&quot;&gt;&lt;img src=&quot;https://jonathanvacher.github.io/assets/icons/pdf_icon.png&quot; float=&quot;right&quot; /&gt;&lt;/a&gt;     		
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;roggerone2019auditory-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;roggerone2019auditory-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{roggerone2019auditory,
  title = {Auditory motion perception emerges from successive sound localizations integrated over time},
  author = {Roggerone, Vincent and Vacher, Jonathan and Tarlao, Cynthia and Guastavino, Catherine},
  journal = {Scientific Reports},
  volume = {9},
  pages = {16437},
  year = {2019},
  publisher = {Nature Publishing Group},
  doi = {10.1038/s41598-019-52742-0}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;script&gt;
function myFunctionroggerone2019auditory() {
  var x = document.getElementById(&quot;roggerone2019auditory-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
/*
 &lt;div class=&quot;column0&quot;&gt;
  	&lt;/div&gt; */
&lt;/script&gt;
&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-roggerone2019auditory&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;Humans rely on auditory information to estimate the path of moving sound sources. But unlike in vision, the existence of motion-sensitive mechanisms in audition is still open to debate. Psychophysical studies indicate that auditory motion perception emerges from successive localization, but existing models fail to predict experimental results. However, these models do not account for any temporal integration. We propose a new model tracking motion using successive localization snapshots but integrated over time. This model is derived from psychophysical experiments on the upper limit for circular auditory motion perception (UL), defned as the speed above which humans no longer identify the direction of sounds spinning around them. Our model predicts ULs measured with diferent stimuli using solely static localization cues. The temporal integration blurs these localization cues rendering them unreliable at high speeds, which results in the UL. Our fndings indicate that auditory motion perception does not require motion-sensitive mechanisms.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><category term="publications" /><summary type="html">Roggerone, V., Vacher, J., Tarlao, C. &amp;amp; Guastavino, C. Auditory motion perception emerges from successive sound localizations integrated over time. Scientific Reports 9, 16437 (2019). @article{roggerone2019auditory, title = {Auditory motion perception emerges from successive sound localizations integrated over time}, author = {Roggerone, Vincent and Vacher, Jonathan and Tarlao, Cynthia and Guastavino, Catherine}, journal = {Scientific Reports}, volume = {9}, pages = {16437}, year = {2019}, publisher = {Nature Publishing Group}, doi = {10.1038/s41598-019-52742-0} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/figure-auditory-roggerone-2019.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/figure-auditory-roggerone-2019.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Contributed talk at ECVP !</title><link href="https://jonathanvacher.github.io/conferences/2019-08-29-talk-ecvp/" rel="alternate" type="text/html" title="Contributed talk at ECVP !" /><published>2019-08-29T00:00:00+02:00</published><updated>2019-08-29T00:00:00+02:00</updated><id>https://jonathanvacher.github.io/conferences/talk-ecvp</id><content type="html" xml:base="https://jonathanvacher.github.io/conferences/2019-08-29-talk-ecvp/">&lt;p&gt;Spatial context in images modulates visual perception reflecting optimization to the statistics of natural images. Popular models based on divisive normalization (ratio between target and context features) offer a link between optimal coding principles and contextual modulation in cortex. Here, we apply this framework to perceptual grouping in natural images, and more specifically to contour integration. First, we show that a successful model of image statistics based on normalization (termed Gaussian Scale Mixture, GSM) learns dependencies between colinear features in natural images. We then show analytically that image regions with strong normalization are statistical outliers of the model, and use this insight to distinguish high-salience regions due to high contrast from those corresponding to contours. To this aim, we extend the model to a mixture of GSMs, with each component encoding a specific orientation and curvature. Our model performs competitively on contour detection in natural images from the BSD500 database. We further evaluate our model by comparing its performance on iso-oriented Gabor elements embedded in Gabor noise (‘snakes’) to the psychophysics literature. Our model thus serves as an ideal observer for contour integration and a basis for future experiments on natural image segmentation.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><category term="conferences" /><summary type="html">Spatial context in images modulates visual perception reflecting optimization to the statistics of natural images. Popular models based on divisive normalization (ratio between target and context features) offer a link between optimal coding principles and contextual modulation in cortex. Here, we apply this framework to perceptual grouping in natural images, and more specifically to contour integration. First, we show that a successful model of image statistics based on normalization (termed Gaussian Scale Mixture, GSM) learns dependencies between colinear features in natural images. We then show analytically that image regions with strong normalization are statistical outliers of the model, and use this insight to distinguish high-salience regions due to high contrast from those corresponding to contours. To this aim, we extend the model to a mixture of GSMs, with each component encoding a specific orientation and curvature. Our model performs competitively on contour detection in natural images from the BSD500 database. We further evaluate our model by comparing its performance on iso-oriented Gabor elements embedded in Gabor noise (‘snakes’) to the psychophysics literature. Our model thus serves as an ideal observer for contour integration and a basis for future experiments on natural image segmentation.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/talk-ecvp-2019.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/talk-ecvp-2019.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis</title><link href="https://jonathanvacher.github.io/publications/2019-05-25-New-preprint/" rel="alternate" type="text/html" title="Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis" /><published>2019-05-25T00:00:00+02:00</published><updated>2019-05-25T00:00:00+02:00</updated><id>https://jonathanvacher.github.io/publications/New-preprint</id><content type="html" xml:base="https://jonathanvacher.github.io/publications/2019-05-25-New-preprint/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;We propose a flexible framework for mixture models. We apply this framework to natural image segmentation using deepnet features at all layers. We show that these mixture models can achieve state-of-the-art boundary scores.&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-vacher2019combining&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column1 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 0px;
}

.column2 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 8px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}

.btn{
  width: 90px;
  height: 25px;
  background: url('https://jonathanvacher.github.io/assets/icons/BibTeX_logo.png') no-repeat center;
  background-color: #e7e7e7;
  border-radius: 8px;
}

.inline{
  display: inline-block;
}
&lt;/style&gt;

&lt;span id=&quot;post2-vacher2019combining&quot;&gt;Vacher, J. &amp;amp; Coen-Cagli, R. Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis. &lt;i&gt;arXiv preprint arXiv:1905.10629&lt;/i&gt; (2019).&lt;/span&gt;
&lt;div class=&quot;inline&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;column1&quot;&gt;
        &lt;button class=&quot;btn&quot; onclick=&quot;myFunctionvacher2019combining()&quot;&gt;&lt;/button&gt; 
        &lt;/div&gt;
        &lt;div class=&quot;column2&quot;&gt;
        &lt;a href=&quot;/pdf/vacher2019combining.pdf&quot;&gt;&lt;img src=&quot;https://jonathanvacher.github.io/assets/icons/pdf_icon.png&quot; float=&quot;right&quot; /&gt;&lt;/a&gt;     		
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;vacher2019combining-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;vacher2019combining-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{vacher2019combining,
  title = {Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis},
  author = {Vacher, Jonathan and Coen-Cagli, Ruben},
  journal = {arXiv preprint arXiv:1905.10629},
  year = {2019}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;script&gt;
function myFunctionvacher2019combining() {
  var x = document.getElementById(&quot;vacher2019combining-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
/*
 &lt;div class=&quot;column0&quot;&gt;
  	&lt;/div&gt; */
&lt;/script&gt;
&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-vacher2019combining&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;Finite mixture models for clustering can often be improved by adding a regularization that is specific to the topology of the data. For instance, mixtures are common in unsupervised image segmentation, and typically rely on averaging the posterior mixing probabilities of spatially adjacent data points (i.e. smoothing). However, this approach has had limited success with natural images. Here we make three contributions. First, we show that a Dirichlet prior with an appropriate choice of parameters allows – using the Expectation-Maximization approach – to define any linear update rule for the mixing probabilities, including many smoothing regularizations as special cases. Second, we demonstrate how to use this flexible design of the update rule to propagate segmentation information across layers of a deep network, and to train mixtures jointly across layers. Third, we compare the standard Gaussian mixture and the Student-t mixture, which is known to better capture the statistics of low-level visual features. We show that our models achieve competitive performance in natural image segmentation, with the Student-t mixtures reaching state-of-the art on boundaries scores. We also demonstrate how to exploit the resulting multilayer probabilistic generative model to synthesize naturalistic images beyond uniform textures.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><category term="publications" /><summary type="html">Vacher, J. &amp;amp; Coen-Cagli, R. Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis. arXiv preprint arXiv:1905.10629 (2019). @article{vacher2019combining, title = {Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis}, author = {Vacher, Jonathan and Coen-Cagli, Ruben}, journal = {arXiv preprint arXiv:1905.10629}, year = {2019} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/combining.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/combining.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Probabilistic Model of Visual Segmentation</title><link href="https://jonathanvacher.github.io/publications/2019-04-30-New-preprint/" rel="alternate" type="text/html" title="Probabilistic Model of Visual Segmentation" /><published>2019-04-30T00:00:00+02:00</published><updated>2019-04-30T00:00:00+02:00</updated><id>https://jonathanvacher.github.io/publications/New-preprint</id><content type="html" xml:base="https://jonathanvacher.github.io/publications/2019-04-30-New-preprint/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;A probabilistic model of visual segmentation with some insight about human uncertainties in segmentation.&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-vacher2019probabilistic&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column1 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 0px;
}

.column2 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 8px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}

.btn{
  width: 90px;
  height: 25px;
  background: url('https://jonathanvacher.github.io/assets/icons/BibTeX_logo.png') no-repeat center;
  background-color: #e7e7e7;
  border-radius: 8px;
}

.inline{
  display: inline-block;
}
&lt;/style&gt;

&lt;span id=&quot;post2-vacher2019probabilistic&quot;&gt;Vacher, J., Mamassian, P. &amp;amp; Coen-Cagli, R. Probabilistic Model of Visual Segmentation. &lt;i&gt;arXiv preprint arXiv:1806.00111&lt;/i&gt; (2019).&lt;/span&gt;
&lt;div class=&quot;inline&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;column1&quot;&gt;
        &lt;button class=&quot;btn&quot; onclick=&quot;myFunctionvacher2019probabilistic()&quot;&gt;&lt;/button&gt; 
        &lt;/div&gt;
        &lt;div class=&quot;column2&quot;&gt;
        &lt;a href=&quot;/pdf/vacher2019probabilistic.pdf&quot;&gt;&lt;img src=&quot;https://jonathanvacher.github.io/assets/icons/pdf_icon.png&quot; float=&quot;right&quot; /&gt;&lt;/a&gt;     		
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;vacher2019probabilistic-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;vacher2019probabilistic-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{vacher2019probabilistic,
  title = {Probabilistic Model of Visual Segmentation},
  author = {Vacher, Jonathan and Mamassian, Pascal and Coen-Cagli, Ruben},
  journal = {arXiv preprint arXiv:1806.00111},
  year = {2019}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;script&gt;
function myFunctionvacher2019probabilistic() {
  var x = document.getElementById(&quot;vacher2019probabilistic-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
/*
 &lt;div class=&quot;column0&quot;&gt;
  	&lt;/div&gt; */
&lt;/script&gt;
&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-vacher2019probabilistic&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;Visual segmentation is a key perceptual function that partitions visual space and allows for detection, recognition and discrimination of objects in complex environments. The processes underlying human segmentation of natural images are still poorly understood. In part, this is because we lack segmentation models consistent with experimental and theoretical knowledge in visual neuroscience. Biological sensory systems have been shown to approximate probabilistic inference to interpret their inputs. This requires a generative model that captures both the statistics of the sensory inputs and expectations about the causes of those inputs. Following this hypothesis, we propose a probabilistic generative model of visual segmentation that combines knowledge about 1) the sensitivity of neurons in the visual cortex to statistical regularities in natural images; and 2) the preference of humans to form contiguous partitions of visual space. We develop an efficient algorithm for training and inference based on expectation-maximization and validate it on synthetic data. Importantly, with the appropriate choice of the prior, we derive an intuitive closed–form update rule for assigning pixels to segments: at each iteration, the pixel assignment probabilities to segments is the sum of the evidence (i.e. local pixel statistics) and prior (i.e. the assignments of neighboring pixels) weighted by their relative uncertainty. The model performs competitively on natural images from the Berkeley Segmentation Dataset (BSD), and we illustrate how the likelihood and prior components improve segmentation relative to traditional mixture models. Furthermore, our model explains some variability across human subjects as reflecting local uncertainty about the number of segments. Our model thus provides a viable approach to probe human visual segmentation.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><category term="publications" /><summary type="html">Vacher, J., Mamassian, P. &amp;amp; Coen-Cagli, R. Probabilistic Model of Visual Segmentation. arXiv preprint arXiv:1806.00111 (2019). @article{vacher2019probabilistic, title = {Probabilistic Model of Visual Segmentation}, author = {Vacher, Jonathan and Mamassian, Pascal and Coen-Cagli, Ruben}, journal = {arXiv preprint arXiv:1806.00111}, year = {2019} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/probabilistic-seg.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/probabilistic-seg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Bayesian modeling of motion perception using dynamical stochastic textures</title><link href="https://jonathanvacher.github.io/publications/2018-11-21-New-paper-in-Neural-Computation/" rel="alternate" type="text/html" title="Bayesian modeling of motion perception using dynamical stochastic textures" /><published>2018-11-21T00:00:00+01:00</published><updated>2018-11-21T00:00:00+01:00</updated><id>https://jonathanvacher.github.io/publications/New-paper-in-Neural-Computation</id><content type="html" xml:base="https://jonathanvacher.github.io/publications/2018-11-21-New-paper-in-Neural-Computation/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;Reproduction of the Heeger-Bergen pyramid-based texture analysis/synthesis algorithm. Code in C and algorithmic details&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-Vacher2018bayesian&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column1 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 0px;
}

.column2 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 8px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}

.btn{
  width: 90px;
  height: 25px;
  background: url('https://jonathanvacher.github.io/assets/icons/BibTeX_logo.png') no-repeat center;
  background-color: #e7e7e7;
  border-radius: 8px;
}

.inline{
  display: inline-block;
}
&lt;/style&gt;

&lt;span id=&quot;post2-Vacher2018bayesian&quot;&gt;Vacher, J., Meso, A. I., Perrinet, L. U. &amp;amp; Peyré, G. Bayesian modeling of motion perception using dynamical stochastic textures. &lt;i&gt;Neural computation&lt;/i&gt; &lt;b&gt;30&lt;/b&gt;, 3355–3392 (2018).&lt;/span&gt;
&lt;div class=&quot;inline&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;column1&quot;&gt;
        &lt;button class=&quot;btn&quot; onclick=&quot;myFunctionVacher2018bayesian()&quot;&gt;&lt;/button&gt; 
        &lt;/div&gt;
        &lt;div class=&quot;column2&quot;&gt;
        &lt;a href=&quot;/pdf/Vacher2018bayesian.pdf&quot;&gt;&lt;img src=&quot;https://jonathanvacher.github.io/assets/icons/pdf_icon.png&quot; float=&quot;right&quot; /&gt;&lt;/a&gt;     		
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;Vacher2018bayesian-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;Vacher2018bayesian-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{Vacher2018bayesian,
  title = {Bayesian modeling of motion perception using dynamical stochastic textures},
  author = {Vacher, Jonathan and Meso, Andrew Isaac and Perrinet, Laurent U and Peyr{\'e}, Gabriel},
  journal = {Neural computation},
  volume = {30},
  number = {12},
  pages = {3355--3392},
  year = {2018},
  publisher = {MIT Press},
  doi = {10.1162/neco_a_01142}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;script&gt;
function myFunctionVacher2018bayesian() {
  var x = document.getElementById(&quot;Vacher2018bayesian-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
/*
 &lt;div class=&quot;column0&quot;&gt;
  	&lt;/div&gt; */
&lt;/script&gt;
&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-Vacher2018bayesian&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;A common practice to account for psychophysical biases in vision is to frame them as consequences of a dynamic process relying on optimal inference with respect to a generative model. The present study details the complete formulation of such a gen-erative model intended to probe visual motion perception. It is first derived in a set of axiomatic steps constrained by biological plausibility. We then extend previous con-tributions by detailing three equivalent formulations of the Gaussian dynamic texture model. First, the composite dynamic textures are constructed by the random aggrega-tion of warped patterns, which can be viewed as 3D Gaussian fields. Second, these textures are cast as solutions to a stochastic partial differential equation (sPDE). This essential step enables real time, on-the-fly, texture synthesis using time-discretized auto-regressive processes. It also allows for the derivation of a local motion-energy model, which corresponds to the log-likelihood of the probability density. The log-likelihoods are finally essential for the construction of a Bayesian inference framework. We use the model to probe speed perception in humans psychophysically using zoom-like changes in stimulus spatial frequency content. The likelihood is contained within the genera-tive model and we chose a slow speed prior consistent with previous literature. We then validated the fitting process of the model using synthesized data. The human data replicates previous findings that relative perceived speed is positively biased by spatial frequency increments. The effect cannot be fully accounted for by previous models, but the current prior acting on the spatio-temporal likelihoods has proved necessary in accounting for the perceptual bias.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><category term="publications" /><summary type="html">Vacher, J., Meso, A. I., Perrinet, L. U. &amp;amp; Peyré, G. Bayesian modeling of motion perception using dynamical stochastic textures. Neural computation 30, 3355–3392 (2018). @article{Vacher2018bayesian, title = {Bayesian modeling of motion perception using dynamical stochastic textures}, author = {Vacher, Jonathan and Meso, Andrew Isaac and Perrinet, Laurent U and Peyr{\'e}, Gabriel}, journal = {Neural computation}, volume = {30}, number = {12}, pages = {3355--3392}, year = {2018}, publisher = {MIT Press}, doi = {10.1162/neco_a_01142} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/neco-2018.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/neco-2018.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>