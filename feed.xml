<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="https://jonathanvacher.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://jonathanvacher.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2020-06-19T16:38:38-04:00</updated><id>https://jonathanvacher.github.io/feed.xml</id><title type="html">Jonathan Vacher</title><subtitle>Postdoc @ Albert Einstein, New-York
</subtitle><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><entry><title type="html">Texture Interpolation for Probing Visual Perception</title><link href="https://jonathanvacher.github.io/publications/2020-06-09-New-preprint/" rel="alternate" type="text/html" title="Texture Interpolation for Probing Visual Perception" /><published>2020-06-09T00:00:00-04:00</published><updated>2020-06-09T00:00:00-04:00</updated><id>https://jonathanvacher.github.io/publications/New-preprint</id><content type="html" xml:base="https://jonathanvacher.github.io/publications/2020-06-09-New-preprint/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;We use the Optimal Transport framework to interpolate between textures and use these textures in a perceptual task and record the macaque visual cortex.
&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-vacher2020texture&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column1 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 0px;
}

.column2 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 8px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}

.btn{
  width: 90px;
  height: 25px;
  background: url('https://jonathanvacher.github.io/assets/icons/BibTeX_logo.png') no-repeat center;
  background-color: #e7e7e7;
  border-radius: 8px;
}

.inline{
  display: inline-block;
}
&lt;/style&gt;

&lt;span id=&quot;post2-vacher2020texture&quot;&gt;Vacher, J., Davila, A., Kohn, A. &amp;amp; Coen-Cagli, R. Texture Interpolation for Probing Visual Perception. &lt;i&gt;arXiv preprint arXiv:2006.03698&lt;/i&gt; (2020).&lt;/span&gt;
&lt;div class=&quot;inline&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;column1&quot;&gt;
        &lt;button class=&quot;btn&quot; onclick=&quot;myFunctionvacher2020texture()&quot;&gt;&lt;/button&gt; 
        &lt;/div&gt;
        &lt;div class=&quot;column2&quot;&gt;
        &lt;a href=&quot;/pdf/vacher2020texture.pdf&quot;&gt;&lt;img src=&quot;https://jonathanvacher.github.io/assets/icons/pdf_icon.png&quot; float=&quot;right&quot; /&gt;&lt;/a&gt;     		
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;vacher2020texture-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;vacher2020texture-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{vacher2020texture,
  title = {Texture Interpolation for Probing Visual Perception},
  author = {Vacher, Jonathan and Davila, Aida and Kohn, Adam and Coen-Cagli, Ruben},
  journal = {arXiv preprint arXiv:2006.03698},
  year = {2020}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;script&gt;
function myFunctionvacher2020texture() {
  var x = document.getElementById(&quot;vacher2020texture-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
/*
 &lt;div class=&quot;column0&quot;&gt;
  	&lt;/div&gt; */
&lt;/script&gt;
&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-vacher2020texture&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;Texture synthesis models are important to understand visual processing. In particular, statistical approaches based on neurally relevant features have been instrumentalto understanding aspects of visual perception and of neural coding.  New deep learning-based approaches further improve the quality of synthetic textures. Yet, itis still unclear why deep texture synthesis performs so well, and applications ofthis new framework to probe visual perception are scarce. Here, we show that distributions of deep convolutional neural network (CNN) activations of a texture arewell described by elliptical distributions and therefore, following optimal transporttheory, constraining their mean and covariance is sufficient to generate new texturesamples. Then, we propose the natural geodesics (i.e.the shortest path between twopoints) arising with the optimal transport metric to interpolate between arbitrarytextures. The comparison to alternative interpolation methods suggests that oursmatches more closely the geometry of texture perception, and is better suited tostudy its statistical nature. We demonstrate our method by measuring the perceptualscale associated to the interpolation parameter in human observers, and the neuralsensitivity of different areas of visual cortex in macaque monkeys.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><summary type="html">Vacher, J., Davila, A., Kohn, A. &amp;amp; Coen-Cagli, R. Texture Interpolation for Probing Visual Perception. arXiv preprint arXiv:2006.03698 (2020). @article{vacher2020texture, title = {Texture Interpolation for Probing Visual Perception}, author = {Vacher, Jonathan and Davila, Aida and Kohn, Adam and Coen-Cagli, Ruben}, journal = {arXiv preprint arXiv:2006.03698}, year = {2020} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/neurips-2020.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/neurips-2020.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Probabilistic reachability and control synthesis for stochastic switched systems using the tamed Euler method.</title><link href="https://jonathanvacher.github.io/publications/2020-01-14-New-paper-in-NAHS/" rel="alternate" type="text/html" title="Probabilistic reachability and control synthesis for stochastic switched systems using the tamed Euler method." /><published>2020-01-14T00:00:00-05:00</published><updated>2020-01-14T00:00:00-05:00</updated><id>https://jonathanvacher.github.io/publications/New-paper-in-NAHS</id><content type="html" xml:base="https://jonathanvacher.github.io/publications/2020-01-14-New-paper-in-NAHS/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;We combined our knowledge to apply a direct symbolic control method to SDEs. We guarantee that solutions remain in a tube with high-proba!&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-lecoent2020probabilistic&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column1 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 0px;
}

.column2 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 8px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}

.btn{
  width: 90px;
  height: 25px;
  background: url('https://jonathanvacher.github.io/assets/icons/BibTeX_logo.png') no-repeat center;
  background-color: #e7e7e7;
  border-radius: 8px;
}

.inline{
  display: inline-block;
}
&lt;/style&gt;

&lt;span id=&quot;post2-lecoent2020probabilistic&quot;&gt;Le Coënt, A., Fribourg, L., Vacher, J. &amp;amp; Wisniewski, R. Probabilistic reachability and control synthesis for stochastic switched systems using the tamed Euler method. &lt;i&gt;Nonlinear Analysis: Hybrid Systems&lt;/i&gt; &lt;b&gt;36&lt;/b&gt;, 100860 (2020).&lt;/span&gt;
&lt;div class=&quot;inline&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;column1&quot;&gt;
        &lt;button class=&quot;btn&quot; onclick=&quot;myFunctionlecoent2020probabilistic()&quot;&gt;&lt;/button&gt; 
        &lt;/div&gt;
        &lt;div class=&quot;column2&quot;&gt;
        &lt;a href=&quot;/pdf/lecoent2020probabilistic.pdf&quot;&gt;&lt;img src=&quot;https://jonathanvacher.github.io/assets/icons/pdf_icon.png&quot; float=&quot;right&quot; /&gt;&lt;/a&gt;     		
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;lecoent2020probabilistic-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;lecoent2020probabilistic-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{lecoent2020probabilistic,
  title = {Probabilistic reachability and control synthesis for stochastic switched systems using the tamed Euler method},
  author = {Le Co\&quot;ent, Adrien and Fribourg, Laurent and Vacher, Jonathan and Wisniewski, Rafael},
  journal = {Nonlinear Analysis: Hybrid Systems},
  volume = {36},
  pages = {100860},
  year = {2020},
  publisher = {Elsevier},
  doi = {10.1016/j.nahs.2020.100860}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;script&gt;
function myFunctionlecoent2020probabilistic() {
  var x = document.getElementById(&quot;lecoent2020probabilistic-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
/*
 &lt;div class=&quot;column0&quot;&gt;
  	&lt;/div&gt; */
&lt;/script&gt;
&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-lecoent2020probabilistic&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;In this paper, we explain how, under the one-sided Lipschitz (OSL) hypothesis, one can find a mean square error bound for a variant of the Euler–Maruyama approximation method for stochastic switched systems. Subsequently, we explain how this bound can be used to control a stochastic switched system in order to make it reach a target zone with guaranteed minimum probability. The method is illustrated on several examples from the literature.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><summary type="html">Le Coënt, A., Fribourg, L., Vacher, J. &amp;amp; Wisniewski, R. Probabilistic reachability and control synthesis for stochastic switched systems using the tamed Euler method. Nonlinear Analysis: Hybrid Systems 36, 100860 (2020). @article{lecoent2020probabilistic, title = {Probabilistic reachability and control synthesis for stochastic switched systems using the tamed Euler method}, author = {Le Co\&quot;ent, Adrien and Fribourg, Laurent and Vacher, Jonathan and Wisniewski, Rafael}, journal = {Nonlinear Analysis: Hybrid Systems}, volume = {36}, pages = {100860}, year = {2020}, publisher = {Elsevier}, doi = {10.1016/j.nahs.2020.100860} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/nahs-2020.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/nahs-2020.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Auditory motion perception emerges from successive sound localizations integrated over time.</title><link href="https://jonathanvacher.github.io/publications/2019-11-11-New-paper-in-SciRep/" rel="alternate" type="text/html" title="Auditory motion perception emerges from successive sound localizations integrated over time." /><published>2019-11-11T00:00:00-05:00</published><updated>2019-11-11T00:00:00-05:00</updated><id>https://jonathanvacher.github.io/publications/New-paper-in-SciRep</id><content type="html" xml:base="https://jonathanvacher.github.io/publications/2019-11-11-New-paper-in-SciRep/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;We provide a connection between sound localization and sound motion perception through the upper limit (UL) speed of sound direction discrimination. We propose a spectral cue that explains both front-back confusion rates and the variation of the UL speed with the spectral content when accounting for a minimal integration time in the auditory cortex.&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-roggerone2019auditory&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column1 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 0px;
}

.column2 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 8px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}

.btn{
  width: 90px;
  height: 25px;
  background: url('https://jonathanvacher.github.io/assets/icons/BibTeX_logo.png') no-repeat center;
  background-color: #e7e7e7;
  border-radius: 8px;
}

.inline{
  display: inline-block;
}
&lt;/style&gt;

&lt;span id=&quot;post2-roggerone2019auditory&quot;&gt;Roggerone, V., Vacher, J., Tarlao, C. &amp;amp; Guastavino, C. Auditory motion perception emerges from successive sound localizations integrated over time. &lt;i&gt;Scientific Reports&lt;/i&gt; &lt;b&gt;9&lt;/b&gt;, 16437 (2019).&lt;/span&gt;
&lt;div class=&quot;inline&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;column1&quot;&gt;
        &lt;button class=&quot;btn&quot; onclick=&quot;myFunctionroggerone2019auditory()&quot;&gt;&lt;/button&gt; 
        &lt;/div&gt;
        &lt;div class=&quot;column2&quot;&gt;
        &lt;a href=&quot;/pdf/roggerone2019auditory.pdf&quot;&gt;&lt;img src=&quot;https://jonathanvacher.github.io/assets/icons/pdf_icon.png&quot; float=&quot;right&quot; /&gt;&lt;/a&gt;     		
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;roggerone2019auditory-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;roggerone2019auditory-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{roggerone2019auditory,
  title = {Auditory motion perception emerges from successive sound localizations integrated over time},
  author = {Roggerone, Vincent and Vacher, Jonathan and Tarlao, Cynthia and Guastavino, Catherine},
  journal = {Scientific Reports},
  volume = {9},
  pages = {16437},
  year = {2019},
  publisher = {Nature Publishing Group},
  doi = {10.1038/s41598-019-52742-0}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;script&gt;
function myFunctionroggerone2019auditory() {
  var x = document.getElementById(&quot;roggerone2019auditory-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
/*
 &lt;div class=&quot;column0&quot;&gt;
  	&lt;/div&gt; */
&lt;/script&gt;
&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-roggerone2019auditory&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;Humans rely on auditory information to estimate the path of moving sound sources. But unlike in vision, the existence of motion-sensitive mechanisms in audition is still open to debate. Psychophysical studies indicate that auditory motion perception emerges from successive localization, but existing models fail to predict experimental results. However, these models do not account for any temporal integration. We propose a new model tracking motion using successive localization snapshots but integrated over time. This model is derived from psychophysical experiments on the upper limit for circular auditory motion perception (UL), defned as the speed above which humans no longer identify the direction of sounds spinning around them. Our model predicts ULs measured with diferent stimuli using solely static localization cues. The temporal integration blurs these localization cues rendering them unreliable at high speeds, which results in the UL. Our fndings indicate that auditory motion perception does not require motion-sensitive mechanisms.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><summary type="html">Roggerone, V., Vacher, J., Tarlao, C. &amp;amp; Guastavino, C. Auditory motion perception emerges from successive sound localizations integrated over time. Scientific Reports 9, 16437 (2019). @article{roggerone2019auditory, title = {Auditory motion perception emerges from successive sound localizations integrated over time}, author = {Roggerone, Vincent and Vacher, Jonathan and Tarlao, Cynthia and Guastavino, Catherine}, journal = {Scientific Reports}, volume = {9}, pages = {16437}, year = {2019}, publisher = {Nature Publishing Group}, doi = {10.1038/s41598-019-52742-0} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/figure-auditory-roggerone-2019.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/figure-auditory-roggerone-2019.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Contributed talk at ECVP !</title><link href="https://jonathanvacher.github.io/milestones/2019-08-29-talk-ecvp/" rel="alternate" type="text/html" title="Contributed talk at ECVP !" /><published>2019-08-29T00:00:00-04:00</published><updated>2019-08-29T00:00:00-04:00</updated><id>https://jonathanvacher.github.io/milestones/talk-ecvp</id><content type="html" xml:base="https://jonathanvacher.github.io/milestones/2019-08-29-talk-ecvp/">&lt;p&gt;Spatial context in images modulates visual perception reflecting optimization to the statistics of natural images. Popular models based on divisive normalization (ratio between target and context features) offer a link between optimal coding principles and contextual modulation in cortex. Here, we apply this framework to perceptual grouping in natural images, and more specifically to contour integration. First, we show that a successful model of image statistics based on normalization (termed Gaussian Scale Mixture, GSM) learns dependencies between colinear features in natural images. We then show analytically that image regions with strong normalization are statistical outliers of the model, and use this insight to distinguish high-salience regions due to high contrast from those corresponding to contours. To this aim, we extend the model to a mixture of GSMs, with each component encoding a specific orientation and curvature. Our model performs competitively on contour detection in natural images from the BSD500 database. We further evaluate our model by comparing its performance on iso-oriented Gabor elements embedded in Gabor noise (‘snakes’) to the psychophysics literature. Our model thus serves as an ideal observer for contour integration and a basis for future experiments on natural image segmentation.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><summary type="html">Spatial context in images modulates visual perception reflecting optimization to the statistics of natural images. Popular models based on divisive normalization (ratio between target and context features) offer a link between optimal coding principles and contextual modulation in cortex. Here, we apply this framework to perceptual grouping in natural images, and more specifically to contour integration. First, we show that a successful model of image statistics based on normalization (termed Gaussian Scale Mixture, GSM) learns dependencies between colinear features in natural images. We then show analytically that image regions with strong normalization are statistical outliers of the model, and use this insight to distinguish high-salience regions due to high contrast from those corresponding to contours. To this aim, we extend the model to a mixture of GSMs, with each component encoding a specific orientation and curvature. Our model performs competitively on contour detection in natural images from the BSD500 database. We further evaluate our model by comparing its performance on iso-oriented Gabor elements embedded in Gabor noise (‘snakes’) to the psychophysics literature. Our model thus serves as an ideal observer for contour integration and a basis for future experiments on natural image segmentation.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/talk-ecvp.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/talk-ecvp.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis</title><link href="https://jonathanvacher.github.io/publications/2019-05-25-New-preprint/" rel="alternate" type="text/html" title="Combining mixture models with linear mixing updates&amp;#58; multilayer image segmentation and synthesis" /><published>2019-05-25T00:00:00-04:00</published><updated>2019-05-25T00:00:00-04:00</updated><id>https://jonathanvacher.github.io/publications/New-preprint</id><content type="html" xml:base="https://jonathanvacher.github.io/publications/2019-05-25-New-preprint/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;We propose a flexible framework for mixture models. We apply this framework to natural image segmentation using deepnet features at all layers. We show that these mixture models can achieve state-of-the-art boundary scores.&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-vacher2019combining&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column1 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 0px;
}

.column2 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 8px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}

.btn{
  width: 90px;
  height: 25px;
  background: url('https://jonathanvacher.github.io/assets/icons/BibTeX_logo.png') no-repeat center;
  background-color: #e7e7e7;
  border-radius: 8px;
}

.inline{
  display: inline-block;
}
&lt;/style&gt;

&lt;span id=&quot;post2-vacher2019combining&quot;&gt;Vacher, J. &amp;amp; Coen-Cagli, R. Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis. &lt;i&gt;arXiv preprint arXiv:1905.10629&lt;/i&gt; (2019).&lt;/span&gt;
&lt;div class=&quot;inline&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;column1&quot;&gt;
        &lt;button class=&quot;btn&quot; onclick=&quot;myFunctionvacher2019combining()&quot;&gt;&lt;/button&gt; 
        &lt;/div&gt;
        &lt;div class=&quot;column2&quot;&gt;
        &lt;a href=&quot;/pdf/vacher2019combining.pdf&quot;&gt;&lt;img src=&quot;https://jonathanvacher.github.io/assets/icons/pdf_icon.png&quot; float=&quot;right&quot; /&gt;&lt;/a&gt;     		
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;vacher2019combining-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;vacher2019combining-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{vacher2019combining,
  title = {Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis},
  author = {Vacher, Jonathan and Coen-Cagli, Ruben},
  journal = {arXiv preprint arXiv:1905.10629},
  year = {2019}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;script&gt;
function myFunctionvacher2019combining() {
  var x = document.getElementById(&quot;vacher2019combining-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
/*
 &lt;div class=&quot;column0&quot;&gt;
  	&lt;/div&gt; */
&lt;/script&gt;
&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-vacher2019combining&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;Finite mixture models for clustering can often be improved by adding a regularization that is specific to the topology of the data. For instance, mixtures are common in unsupervised image segmentation, and typically rely on averaging the posterior mixing probabilities of spatially adjacent data points (i.e. smoothing). However, this approach has had limited success with natural images. Here we make three contributions. First, we show that a Dirichlet prior with an appropriate choice of parameters allows – using the Expectation-Maximization approach – to define any linear update rule for the mixing probabilities, including many smoothing regularizations as special cases. Second, we demonstrate how to use this flexible design of the update rule to propagate segmentation information across layers of a deep network, and to train mixtures jointly across layers. Third, we compare the standard Gaussian mixture and the Student-t mixture, which is known to better capture the statistics of low-level visual features. We show that our models achieve competitive performance in natural image segmentation, with the Student-t mixtures reaching state-of-the art on boundaries scores. We also demonstrate how to exploit the resulting multilayer probabilistic generative model to synthesize naturalistic images beyond uniform textures.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><summary type="html">Vacher, J. &amp;amp; Coen-Cagli, R. Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis. arXiv preprint arXiv:1905.10629 (2019). @article{vacher2019combining, title = {Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis}, author = {Vacher, Jonathan and Coen-Cagli, Ruben}, journal = {arXiv preprint arXiv:1905.10629}, year = {2019} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/combining.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/combining.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Probabilistic Model of Visual Segmentation</title><link href="https://jonathanvacher.github.io/publications/2019-04-30-New-preprint/" rel="alternate" type="text/html" title="Probabilistic Model of Visual Segmentation" /><published>2019-04-30T00:00:00-04:00</published><updated>2019-04-30T00:00:00-04:00</updated><id>https://jonathanvacher.github.io/publications/New-preprint</id><content type="html" xml:base="https://jonathanvacher.github.io/publications/2019-04-30-New-preprint/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;A probabilistic model of visual segmentation with some insight about human uncertainties in segmentation.&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-vacher2019probabilistic&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column1 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 0px;
}

.column2 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 8px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}

.btn{
  width: 90px;
  height: 25px;
  background: url('https://jonathanvacher.github.io/assets/icons/BibTeX_logo.png') no-repeat center;
  background-color: #e7e7e7;
  border-radius: 8px;
}

.inline{
  display: inline-block;
}
&lt;/style&gt;

&lt;span id=&quot;post2-vacher2019probabilistic&quot;&gt;Vacher, J., Mamassian, P. &amp;amp; Coen-Cagli, R. Probabilistic Model of Visual Segmentation. &lt;i&gt;arXiv preprint arXiv:1806.00111&lt;/i&gt; (2019).&lt;/span&gt;
&lt;div class=&quot;inline&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;column1&quot;&gt;
        &lt;button class=&quot;btn&quot; onclick=&quot;myFunctionvacher2019probabilistic()&quot;&gt;&lt;/button&gt; 
        &lt;/div&gt;
        &lt;div class=&quot;column2&quot;&gt;
        &lt;a href=&quot;/pdf/vacher2019probabilistic.pdf&quot;&gt;&lt;img src=&quot;https://jonathanvacher.github.io/assets/icons/pdf_icon.png&quot; float=&quot;right&quot; /&gt;&lt;/a&gt;     		
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;vacher2019probabilistic-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;vacher2019probabilistic-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{vacher2019probabilistic,
  title = {Probabilistic Model of Visual Segmentation},
  author = {Vacher, Jonathan and Mamassian, Pascal and Coen-Cagli, Ruben},
  journal = {arXiv preprint arXiv:1806.00111},
  year = {2019}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;script&gt;
function myFunctionvacher2019probabilistic() {
  var x = document.getElementById(&quot;vacher2019probabilistic-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
/*
 &lt;div class=&quot;column0&quot;&gt;
  	&lt;/div&gt; */
&lt;/script&gt;
&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-vacher2019probabilistic&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;Visual segmentation is a key perceptual function that partitions visual space and allows for detection, recognition and discrimination of objects in complex environments. The processes underlying human segmentation of natural images are still poorly understood. In part, this is because we lack segmentation models consistent with experimental and theoretical knowledge in visual neuroscience. Biological sensory systems have been shown to approximate probabilistic inference to interpret their inputs. This requires a generative model that captures both the statistics of the sensory inputs and expectations about the causes of those inputs. Following this hypothesis, we propose a probabilistic generative model of visual segmentation that combines knowledge about 1) the sensitivity of neurons in the visual cortex to statistical regularities in natural images; and 2) the preference of humans to form contiguous partitions of visual space. We develop an efficient algorithm for training and inference based on expectation-maximization and validate it on synthetic data. Importantly, with the appropriate choice of the prior, we derive an intuitive closed–form update rule for assigning pixels to segments: at each iteration, the pixel assignment probabilities to segments is the sum of the evidence (i.e. local pixel statistics) and prior (i.e. the assignments of neighboring pixels) weighted by their relative uncertainty. The model performs competitively on natural images from the Berkeley Segmentation Dataset (BSD), and we illustrate how the likelihood and prior components improve segmentation relative to traditional mixture models. Furthermore, our model explains some variability across human subjects as reflecting local uncertainty about the number of segments. Our model thus provides a viable approach to probe human visual segmentation.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><summary type="html">Vacher, J., Mamassian, P. &amp;amp; Coen-Cagli, R. Probabilistic Model of Visual Segmentation. arXiv preprint arXiv:1806.00111 (2019). @article{vacher2019probabilistic, title = {Probabilistic Model of Visual Segmentation}, author = {Vacher, Jonathan and Mamassian, Pascal and Coen-Cagli, Ruben}, journal = {arXiv preprint arXiv:1806.00111}, year = {2019} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/probabilistic-seg.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/probabilistic-seg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Bayesian modeling of motion perception using dynamical stochastic textures</title><link href="https://jonathanvacher.github.io/publications/2018-11-21-New-paper-in-Neural-Computation/" rel="alternate" type="text/html" title="Bayesian modeling of motion perception using dynamical stochastic textures" /><published>2018-11-21T00:00:00-05:00</published><updated>2018-11-21T00:00:00-05:00</updated><id>https://jonathanvacher.github.io/publications/New-paper-in-Neural-Computation</id><content type="html" xml:base="https://jonathanvacher.github.io/publications/2018-11-21-New-paper-in-Neural-Computation/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;Reproduction of the Heeger-Bergen pyramid-based texture analysis/synthesis algorithm. Code in C and algorithmic details&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-Vacher2018bayesian&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column1 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 0px;
}

.column2 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 8px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}

.btn{
  width: 90px;
  height: 25px;
  background: url('https://jonathanvacher.github.io/assets/icons/BibTeX_logo.png') no-repeat center;
  background-color: #e7e7e7;
  border-radius: 8px;
}

.inline{
  display: inline-block;
}
&lt;/style&gt;

&lt;span id=&quot;post2-Vacher2018bayesian&quot;&gt;Vacher, J., Meso, A. I., Perrinet, L. U. &amp;amp; Peyré, G. Bayesian modeling of motion perception using dynamical stochastic textures. &lt;i&gt;Neural computation&lt;/i&gt; &lt;b&gt;30&lt;/b&gt;, 3355–3392 (2018).&lt;/span&gt;
&lt;div class=&quot;inline&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;column1&quot;&gt;
        &lt;button class=&quot;btn&quot; onclick=&quot;myFunctionVacher2018bayesian()&quot;&gt;&lt;/button&gt; 
        &lt;/div&gt;
        &lt;div class=&quot;column2&quot;&gt;
        &lt;a href=&quot;/pdf/Vacher2018bayesian.pdf&quot;&gt;&lt;img src=&quot;https://jonathanvacher.github.io/assets/icons/pdf_icon.png&quot; float=&quot;right&quot; /&gt;&lt;/a&gt;     		
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;Vacher2018bayesian-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;Vacher2018bayesian-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{Vacher2018bayesian,
  title = {Bayesian modeling of motion perception using dynamical stochastic textures},
  author = {Vacher, Jonathan and Meso, Andrew Isaac and Perrinet, Laurent U and Peyr{\'e}, Gabriel},
  journal = {Neural computation},
  volume = {30},
  number = {12},
  pages = {3355--3392},
  year = {2018},
  publisher = {MIT Press},
  doi = {10.1162/neco_a_01142}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;script&gt;
function myFunctionVacher2018bayesian() {
  var x = document.getElementById(&quot;Vacher2018bayesian-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
/*
 &lt;div class=&quot;column0&quot;&gt;
  	&lt;/div&gt; */
&lt;/script&gt;
&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-Vacher2018bayesian&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;A common practice to account for psychophysical biases in vision is to frame them as consequences of a dynamic process relying on optimal inference with respect to a generative model. The present study details the complete formulation of such a gen-erative model intended to probe visual motion perception. It is first derived in a set of axiomatic steps constrained by biological plausibility. We then extend previous con-tributions by detailing three equivalent formulations of the Gaussian dynamic texture model. First, the composite dynamic textures are constructed by the random aggrega-tion of warped patterns, which can be viewed as 3D Gaussian fields. Second, these textures are cast as solutions to a stochastic partial differential equation (sPDE). This essential step enables real time, on-the-fly, texture synthesis using time-discretized auto-regressive processes. It also allows for the derivation of a local motion-energy model, which corresponds to the log-likelihood of the probability density. The log-likelihoods are finally essential for the construction of a Bayesian inference framework. We use the model to probe speed perception in humans psychophysically using zoom-like changes in stimulus spatial frequency content. The likelihood is contained within the genera-tive model and we chose a slow speed prior consistent with previous literature. We then validated the fitting process of the model using synthesized data. The human data replicates previous findings that relative perceived speed is positively biased by spatial frequency increments. The effect cannot be fully accounted for by previous models, but the current prior acting on the spatio-temporal likelihoods has proved necessary in accounting for the perceptual bias.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><summary type="html">Vacher, J., Meso, A. I., Perrinet, L. U. &amp;amp; Peyré, G. Bayesian modeling of motion perception using dynamical stochastic textures. Neural computation 30, 3355–3392 (2018). @article{Vacher2018bayesian, title = {Bayesian modeling of motion perception using dynamical stochastic textures}, author = {Vacher, Jonathan and Meso, Andrew Isaac and Perrinet, Laurent U and Peyr{\'e}, Gabriel}, journal = {Neural computation}, volume = {30}, number = {12}, pages = {3355--3392}, year = {2018}, publisher = {MIT Press}, doi = {10.1162/neco_a_01142} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/neco-2018.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/neco-2018.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Control Synthesis for Stochastic Switched Systems using the Tamed Euler Method</title><link href="https://jonathanvacher.github.io/publications/2018-08-31-New-paper-in-ADHS-Proceedings/" rel="alternate" type="text/html" title="Control Synthesis for Stochastic Switched Systems using the Tamed Euler Method" /><published>2018-08-31T00:00:00-04:00</published><updated>2018-08-31T00:00:00-04:00</updated><id>https://jonathanvacher.github.io/publications/New-paper-in-ADHS-Proceedings</id><content type="html" xml:base="https://jonathanvacher.github.io/publications/2018-08-31-New-paper-in-ADHS-Proceedings/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;
&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-LeCoent2018control&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;

&lt;p&gt;Set control methods applied to stochastic differential equations.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column1 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 0px;
}

.column2 {
  float: left;
  width: 90px;
  height: 25px;
  padding: 8px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}

.btn{
  width: 90px;
  height: 25px;
  background: url('https://jonathanvacher.github.io/assets/icons/BibTeX_logo.png') no-repeat center;
  background-color: #e7e7e7;
  border-radius: 8px;
}

.inline{
  display: inline-block;
}
&lt;/style&gt;

&lt;span id=&quot;post2-LeCoent2018control&quot;&gt;Le Coënt, A., Fribourg, L. &amp;amp; Vacher, J. Control Synthesis for Stochastic Switched Systems using the Tamed Euler Method. in &lt;i&gt;IFAC-PapersOnLine&lt;/i&gt; &lt;b&gt;51&lt;/b&gt;, 259–264 (2018).&lt;/span&gt;
&lt;div class=&quot;inline&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;column1&quot;&gt;
        &lt;button class=&quot;btn&quot; onclick=&quot;myFunctionLeCoent2018control()&quot;&gt;&lt;/button&gt; 
        &lt;/div&gt;
        &lt;div class=&quot;column2&quot;&gt;
        &lt;a href=&quot;/pdf/LeCoent2018control.pdf&quot;&gt;&lt;img src=&quot;https://jonathanvacher.github.io/assets/icons/pdf_icon.png&quot; float=&quot;right&quot; /&gt;&lt;/a&gt;     		
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;LeCoent2018control-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;LeCoent2018control-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@inproceedings{LeCoent2018control,
  title = {Control Synthesis for Stochastic Switched Systems using the Tamed Euler Method},
  journal = {IFAC-PapersOnLine},
  volume = {51},
  number = {16},
  pages = {259 - 264},
  year = {2018},
  booktitle = {6th IFAC Conference on Analysis and Design of Hybrid Systems ADHS 2018},
  issn = {2405-8963},
  doi = {10.1016/j.ifacol.2018.08.044},
  author = {Le Co\&quot;ent, Adrien and Fribourg, Laurent and Vacher, Jonathan},
  keywords = {Stochastic systems, numerical simulation, control system synthesis, switched control systems, nonlinear control systems}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;script&gt;
function myFunctionLeCoent2018control() {
  var x = document.getElementById(&quot;LeCoent2018control-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
/*
 &lt;div class=&quot;column0&quot;&gt;
  	&lt;/div&gt; */
&lt;/script&gt;
&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-LeCoent2018control&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;In this paper, we explain how, under the one-sided Lipschitz (OSL) hypothesis, one can find an error bound for a variant of the Euler-Maruyama approximation method for stochastic switched systems. We then explain how this bound can be used to control stochastic switched switched system in order to stabilize them in a given region. The method is illustrated on several examples of the literature.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><summary type="html">Le Coënt, A., Fribourg, L. &amp;amp; Vacher, J. Control Synthesis for Stochastic Switched Systems using the Tamed Euler Method. in IFAC-PapersOnLine 51, 259–264 (2018). @inproceedings{LeCoent2018control, title = {Control Synthesis for Stochastic Switched Systems using the Tamed Euler Method}, journal = {IFAC-PapersOnLine}, volume = {51}, number = {16}, pages = {259 - 264}, year = {2018}, booktitle = {6th IFAC Conference on Analysis and Design of Hybrid Systems ADHS 2018}, issn = {2405-8963}, doi = {10.1016/j.ifacol.2018.08.044}, author = {Le Co\&quot;ent, Adrien and Fribourg, Laurent and Vacher, Jonathan}, keywords = {Stochastic systems, numerical simulation, control system synthesis, switched control systems, nonlinear control systems} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/adhs-2018.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/adhs-2018.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">New postdoc position</title><link href="https://jonathanvacher.github.io/milestones/2017-09-20-new-postdoc-position/" rel="alternate" type="text/html" title="New postdoc position" /><published>2017-09-20T00:00:00-04:00</published><updated>2017-09-20T00:00:00-04:00</updated><id>https://jonathanvacher.github.io/milestones/new-postdoc-position</id><content type="html" xml:base="https://jonathanvacher.github.io/milestones/2017-09-20-new-postdoc-position/">&lt;p&gt;We work on natural image segmentation. Our goal is to develop a neurally plausible model of image segmentation and to use it to conduct well control psychometric experiments with artificial and natural images.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><summary type="html">We work on natural image segmentation. Our goal is to develop a neurally plausible model of image segmentation and to use it to conduct well control psychometric experiments with artificial and natural images.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/einstein.jpg" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/einstein.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">PhD Defense</title><link href="https://jonathanvacher.github.io/milestones/2017-01-18-phd-defense/" rel="alternate" type="text/html" title="PhD Defense" /><published>2017-01-18T00:00:00-05:00</published><updated>2017-01-18T00:00:00-05:00</updated><id>https://jonathanvacher.github.io/milestones/phd-defense</id><content type="html" xml:base="https://jonathanvacher.github.io/milestones/2017-01-18-phd-defense/">&lt;p&gt;Finally a Doctor !&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;The goal of this thesis is to propose a mathematical model of visual stimulations in order to finely analyze experimental data in psychophysics and electrophysiology. More precisely, it is necessary to develop a set of dynamic, stochastic and parametric stimulations in order to exploit data analysis techniques from Bayesian statistics and machine learning. This problem is important to understand the visual system capacity to integrate and discriminate between stimuli. In particular, the measures performed at different scales (neurons, neural population, cognition) allow to study the particular sensitivities of neurons, their functional organization and their impact on decision making. To this purpose, we propose a set of theoretical, numerical and experimental contributions organized around three principal axes: (1) a Gaussian dynamic texture synthesis model specially crafted to probe vision; (2) a Bayesian observer model that accounts for the positive effect of spatial frequency over speed perception; (3) the use of machine learning techniques to analyze voltage sensitive dye optical imaging and extracellular data. This work, at the crossroads of neurosciences, psychophysics and mathematics is the fruit of several interdisciplinary collaborations.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@ens.fr</email></author><summary type="html">Finally a Doctor !</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jonathanvacher.github.io/assets/img/blog/phd-words-cloud.png" /><media:content medium="image" url="https://jonathanvacher.github.io/assets/img/blog/phd-words-cloud.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>