<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2019-06-03T17:08:32-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Jonathan Vacher</title><subtitle>Postdoc @ Albert Einstein, New-York
</subtitle><author><name>Jonathan Vacher</name><email>jonathan.vacher@einstein.yu.edu</email></author><entry><title type="html">Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis</title><link href="http://localhost:4000/publications/2019-05-25-New-preprint/" rel="alternate" type="text/html" title="Combining mixture models with linear mixing updates&amp;#58; multilayer image segmentation and synthesis" /><published>2019-05-25T00:00:00-04:00</published><updated>2019-05-25T00:00:00-04:00</updated><id>http://localhost:4000/publications/New-preprint</id><content type="html" xml:base="http://localhost:4000/publications/2019-05-25-New-preprint/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;We propose a flexible framework for mixture models. We apply this framework to natural image segmentation using deepnet features at all layers. We show that these mixture models can achieve state-of-the-art boundary scores.&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-vacher2019combining&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column {
  float: left;
  width: 10%;
  padding: 5px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}
&lt;/style&gt;

&lt;span id=&quot;post2-vacher2019combining&quot;&gt;Vacher, J. &amp;amp; Coen-Cagli, R. Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis. &lt;i&gt;arXiv preprint arXiv:1905.10629&lt;/i&gt; (2019).&lt;/span&gt; &lt;br /&gt;

&lt;div class=&quot;row&quot;&gt;
	&lt;div class=&quot;column&quot;&gt;
		&lt;button onclick=&quot;myFunctionvacher2019combining()&quot;&gt;&lt;img src=&quot;http://localhost:4000/assets/icons/BibTeX_logo.png&quot; /&gt;&lt;/button&gt; 
  	&lt;/div&gt;
  	&lt;div class=&quot;column&quot;&gt;
    		&lt;a href=&quot;/pdf/vacher2019combining.pdf&quot;&gt;&lt;img src=&quot;http://localhost:4000/assets/icons/pdf_icon.png&quot; /&gt;&lt;/a&gt;
  	&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;vacher2019combining-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;vacher2019combining-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{vacher2019combining,
  title = {Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis},
  author = {Vacher, Jonathan and Coen-Cagli, Ruben},
  journal = {arXiv preprint arXiv:1905.10629},
  year = {2019}
}
&lt;/pre&gt;
&lt;/div&gt;


&lt;script&gt;
function myFunctionvacher2019combining() {
  var x = document.getElementById(&quot;vacher2019combining-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
&lt;/script&gt;

&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-vacher2019combining&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;Finite mixture models for clustering can often be improved by adding a regularization that is specific to the topology of the data. For instance, mixtures are common in unsupervised image segmentation, and typically rely on averaging the posterior mixing probabilities of spatially adjacent data points (i.e. smoothing). However, this approach has had limited success with natural images. Here we make three contributions. First, we show that a Dirichlet prior with an appropriate choice of parameters allows – using the Expectation-Maximization approach – to define any linear update rule for the mixing probabilities, including many smoothing regularizations as special cases. Second, we demonstrate how to use this flexible design of the update rule to propagate segmentation information across layers of a deep network, and to train mixtures jointly across layers. Third, we compare the standard Gaussian mixture and the Student-t mixture, which is known to better capture the statistics of low-level visual features. We show that our models achieve competitive performance in natural image segmentation, with the Student-t mixtures reaching state-of-the art on boundaries scores. We also demonstrate how to exploit the resulting multilayer probabilistic generative model to synthesize naturalistic images beyond uniform textures.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@einstein.yu.edu</email></author><summary type="html">Vacher, J. &amp;amp; Coen-Cagli, R. Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis. arXiv preprint arXiv:1905.10629 (2019). @article{vacher2019combining, title = {Combining mixture models with linear mixing updates: multilayer image segmentation and synthesis}, author = {Vacher, Jonathan and Coen-Cagli, Ruben}, journal = {arXiv preprint arXiv:1905.10629}, year = {2019} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/combining.png" /></entry><entry><title type="html">Probabilistic Model of Visual Segmentation</title><link href="http://localhost:4000/publications/2019-04-30-New-preprint/" rel="alternate" type="text/html" title="Probabilistic Model of Visual Segmentation" /><published>2019-04-30T00:00:00-04:00</published><updated>2019-04-30T00:00:00-04:00</updated><id>http://localhost:4000/publications/New-preprint</id><content type="html" xml:base="http://localhost:4000/publications/2019-04-30-New-preprint/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;A probabilistic model of visual segmentation with some insight about human uncertainties in segmentation.&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-vacher2019probabilistic&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column {
  float: left;
  width: 10%;
  padding: 5px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}
&lt;/style&gt;

&lt;span id=&quot;post2-vacher2019probabilistic&quot;&gt;Vacher, J., Mamassian, P. &amp;amp; Coen-Cagli, R. Probabilistic Model of Visual Segmentation. &lt;i&gt;arXiv preprint arXiv:1806.00111&lt;/i&gt; (2019).&lt;/span&gt; &lt;br /&gt;

&lt;div class=&quot;row&quot;&gt;
	&lt;div class=&quot;column&quot;&gt;
		&lt;button onclick=&quot;myFunctionvacher2019probabilistic()&quot;&gt;&lt;img src=&quot;http://localhost:4000/assets/icons/BibTeX_logo.png&quot; /&gt;&lt;/button&gt; 
  	&lt;/div&gt;
  	&lt;div class=&quot;column&quot;&gt;
    		&lt;a href=&quot;/pdf/vacher2019probabilistic.pdf&quot;&gt;&lt;img src=&quot;http://localhost:4000/assets/icons/pdf_icon.png&quot; /&gt;&lt;/a&gt;
  	&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;vacher2019probabilistic-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;vacher2019probabilistic-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{vacher2019probabilistic,
  title = {Probabilistic Model of Visual Segmentation},
  author = {Vacher, Jonathan and Mamassian, Pascal and Coen-Cagli, Ruben},
  journal = {arXiv preprint arXiv:1806.00111},
  year = {2019}
}
&lt;/pre&gt;
&lt;/div&gt;


&lt;script&gt;
function myFunctionvacher2019probabilistic() {
  var x = document.getElementById(&quot;vacher2019probabilistic-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
&lt;/script&gt;

&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-vacher2019probabilistic&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;Visual segmentation is a key perceptual function that partitions visual space and allows for detection, recognition and discrimination of objects in complex environments. The processes underlying human segmentation of natural images are still poorly understood. In part, this is because we lack segmentation models consistent with experimental and theoretical knowledge in visual neuroscience. Biological sensory systems have been shown to approximate probabilistic inference to interpret their inputs. This requires a generative model that captures both the statistics of the sensory inputs and expectations about the causes of those inputs. Following this hypothesis, we propose a probabilistic generative model of visual segmentation that combines knowledge about 1) the sensitivity of neurons in the visual cortex to statistical regularities in natural images; and 2) the preference of humans to form contiguous partitions of visual space. We develop an efficient algorithm for training and inference based on expectation-maximization and validate it on synthetic data. Importantly, with the appropriate choice of the prior, we derive an intuitive closed–form update rule for assigning pixels to segments: at each iteration, the pixel assignment probabilities to segments is the sum of the evidence (i.e. local pixel statistics) and prior (i.e. the assignments of neighboring pixels) weighted by their relative uncertainty. The model performs competitively on natural images from the Berkeley Segmentation Dataset (BSD), and we illustrate how the likelihood and prior components improve segmentation relative to traditional mixture models. Furthermore, our model explains some variability across human subjects as reflecting local uncertainty about the number of segments. Our model thus provides a viable approach to probe human visual segmentation.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@einstein.yu.edu</email></author><summary type="html">Vacher, J., Mamassian, P. &amp;amp; Coen-Cagli, R. Probabilistic Model of Visual Segmentation. arXiv preprint arXiv:1806.00111 (2019). @article{vacher2019probabilistic, title = {Probabilistic Model of Visual Segmentation}, author = {Vacher, Jonathan and Mamassian, Pascal and Coen-Cagli, Ruben}, journal = {arXiv preprint arXiv:1806.00111}, year = {2019} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/probabilistic-seg.png" /></entry><entry><title type="html">Bayesian modeling of motion perception using dynamical stochastic textures</title><link href="http://localhost:4000/publications/2018-11-21-New-paper-in-Neural-Computation/" rel="alternate" type="text/html" title="Bayesian modeling of motion perception using dynamical stochastic textures" /><published>2018-11-21T00:00:00-05:00</published><updated>2018-11-21T00:00:00-05:00</updated><id>http://localhost:4000/publications/New-paper-in-Neural-Computation</id><content type="html" xml:base="http://localhost:4000/publications/2018-11-21-New-paper-in-Neural-Computation/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;

&lt;p&gt;Reproduction of the Heeger-Bergen pyramid-based texture analysis/synthesis algorithm. Code in C and algorithmic details&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-Vacher2018bayesian&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column {
  float: left;
  width: 10%;
  padding: 5px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}
&lt;/style&gt;

&lt;span id=&quot;post2-Vacher2018bayesian&quot;&gt;Vacher, J., Meso, A. I., Perrinet, L. U. &amp;amp; Peyré, G. Bayesian modeling of motion perception using dynamical stochastic textures. &lt;i&gt;Neural computation&lt;/i&gt; &lt;b&gt;30&lt;/b&gt;, 3355–3392 (2018).&lt;/span&gt; &lt;br /&gt;

&lt;div class=&quot;row&quot;&gt;
	&lt;div class=&quot;column&quot;&gt;
		&lt;button onclick=&quot;myFunctionVacher2018bayesian()&quot;&gt;&lt;img src=&quot;http://localhost:4000/assets/icons/BibTeX_logo.png&quot; /&gt;&lt;/button&gt; 
  	&lt;/div&gt;
  	&lt;div class=&quot;column&quot;&gt;
    		&lt;a href=&quot;/pdf/Vacher2018bayesian.pdf&quot;&gt;&lt;img src=&quot;http://localhost:4000/assets/icons/pdf_icon.png&quot; /&gt;&lt;/a&gt;
  	&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;Vacher2018bayesian-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;Vacher2018bayesian-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{Vacher2018bayesian,
  title = {Bayesian modeling of motion perception using dynamical stochastic textures},
  author = {Vacher, Jonathan and Meso, Andrew Isaac and Perrinet, Laurent U and Peyr{\'e}, Gabriel},
  journal = {Neural computation},
  volume = {30},
  number = {12},
  pages = {3355--3392},
  year = {2018},
  publisher = {MIT Press},
  doi = {10.1162/neco_a_01142}
}
&lt;/pre&gt;
&lt;/div&gt;


&lt;script&gt;
function myFunctionVacher2018bayesian() {
  var x = document.getElementById(&quot;Vacher2018bayesian-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
&lt;/script&gt;

&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-Vacher2018bayesian&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;A common practice to account for psychophysical biases in vision is to frame them as consequences of a dynamic process relying on optimal inference with respect to a generative model. The present study details the complete formulation of such a gen-erative model intended to probe visual motion perception. It is first derived in a set of axiomatic steps constrained by biological plausibility. We then extend previous con-tributions by detailing three equivalent formulations of the Gaussian dynamic texture model. First, the composite dynamic textures are constructed by the random aggrega-tion of warped patterns, which can be viewed as 3D Gaussian fields. Second, these textures are cast as solutions to a stochastic partial differential equation (sPDE). This essential step enables real time, on-the-fly, texture synthesis using time-discretized auto-regressive processes. It also allows for the derivation of a local motion-energy model, which corresponds to the log-likelihood of the probability density. The log-likelihoods are finally essential for the construction of a Bayesian inference framework. We use the model to probe speed perception in humans psychophysically using zoom-like changes in stimulus spatial frequency content. The likelihood is contained within the genera-tive model and we chose a slow speed prior consistent with previous literature. We then validated the fitting process of the model using synthesized data. The human data replicates previous findings that relative perceived speed is positively biased by spatial frequency increments. The effect cannot be fully accounted for by previous models, but the current prior acting on the spatio-temporal likelihoods has proved necessary in accounting for the perceptual bias.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@einstein.yu.edu</email></author><summary type="html">Vacher, J., Meso, A. I., Perrinet, L. U. &amp;amp; Peyré, G. Bayesian modeling of motion perception using dynamical stochastic textures. Neural computation 30, 3355–3392 (2018). @article{Vacher2018bayesian, title = {Bayesian modeling of motion perception using dynamical stochastic textures}, author = {Vacher, Jonathan and Meso, Andrew Isaac and Perrinet, Laurent U and Peyr{\'e}, Gabriel}, journal = {Neural computation}, volume = {30}, number = {12}, pages = {3355--3392}, year = {2018}, publisher = {MIT Press}, doi = {10.1162/neco_a_01142} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/neco-2018.png" /></entry><entry><title type="html">Control Synthesis for Stochastic Switched Systems using the Tamed Euler Method</title><link href="http://localhost:4000/publications/2018-08-31-New-paper-in-ADHS-Proceedings/" rel="alternate" type="text/html" title="Control Synthesis for Stochastic Switched Systems using the Tamed Euler Method" /><published>2018-08-31T00:00:00-04:00</published><updated>2018-08-31T00:00:00-04:00</updated><id>http://localhost:4000/publications/New-paper-in-ADHS-Proceedings</id><content type="html" xml:base="http://localhost:4000/publications/2018-08-31-New-paper-in-ADHS-Proceedings/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;
&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-LeCoent2018control&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;

&lt;p&gt;Set control methods applied to stochastic differential equations.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column {
  float: left;
  width: 10%;
  padding: 5px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}
&lt;/style&gt;

&lt;span id=&quot;post2-LeCoent2018control&quot;&gt;Le Coënt, A., Fribourg, L. &amp;amp; Vacher, J. Control Synthesis for Stochastic Switched Systems using the Tamed Euler Method. in &lt;i&gt;IFAC-PapersOnLine&lt;/i&gt; &lt;b&gt;51&lt;/b&gt;, 259–264 (2018).&lt;/span&gt; &lt;br /&gt;

&lt;div class=&quot;row&quot;&gt;
	&lt;div class=&quot;column&quot;&gt;
		&lt;button onclick=&quot;myFunctionLeCoent2018control()&quot;&gt;&lt;img src=&quot;http://localhost:4000/assets/icons/BibTeX_logo.png&quot; /&gt;&lt;/button&gt; 
  	&lt;/div&gt;
  	&lt;div class=&quot;column&quot;&gt;
    		&lt;a href=&quot;/pdf/LeCoent2018control.pdf&quot;&gt;&lt;img src=&quot;http://localhost:4000/assets/icons/pdf_icon.png&quot; /&gt;&lt;/a&gt;
  	&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;LeCoent2018control-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;LeCoent2018control-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@inproceedings{LeCoent2018control,
  title = {Control Synthesis for Stochastic Switched Systems using the Tamed Euler Method},
  journal = {IFAC-PapersOnLine},
  volume = {51},
  number = {16},
  pages = {259 - 264},
  year = {2018},
  booktitle = {6th IFAC Conference on Analysis and Design of Hybrid Systems ADHS 2018},
  issn = {2405-8963},
  doi = {10.1016/j.ifacol.2018.08.044},
  author = {Le Co\&quot;ent, Adrien and Fribourg, Laurent and Vacher, Jonathan},
  keywords = {Stochastic systems, numerical simulation, control system synthesis, switched control systems, nonlinear control systems}
}
&lt;/pre&gt;
&lt;/div&gt;


&lt;script&gt;
function myFunctionLeCoent2018control() {
  var x = document.getElementById(&quot;LeCoent2018control-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
&lt;/script&gt;

&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-LeCoent2018control&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;In this paper, we explain how, under the one-sided Lipschitz (OSL) hypothesis, one can find an error bound for a variant of the Euler-Maruyama approximation method for stochastic switched systems. We then explain how this bound can be used to control stochastic switched switched system in order to stabilize them in a given region. The method is illustrated on several examples of the literature.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@einstein.yu.edu</email></author><summary type="html">Le Coënt, A., Fribourg, L. &amp;amp; Vacher, J. Control Synthesis for Stochastic Switched Systems using the Tamed Euler Method. in IFAC-PapersOnLine 51, 259–264 (2018). @inproceedings{LeCoent2018control, title = {Control Synthesis for Stochastic Switched Systems using the Tamed Euler Method}, journal = {IFAC-PapersOnLine}, volume = {51}, number = {16}, pages = {259 - 264}, year = {2018}, booktitle = {6th IFAC Conference on Analysis and Design of Hybrid Systems ADHS 2018}, issn = {2405-8963}, doi = {10.1016/j.ifacol.2018.08.044}, author = {Le Co\&quot;ent, Adrien and Fribourg, Laurent and Vacher, Jonathan}, keywords = {Stochastic systems, numerical simulation, control system synthesis, switched control systems, nonlinear control systems} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/adhs-2018.png" /></entry><entry><title type="html">New postdoc position</title><link href="http://localhost:4000/milestones/2017-09-20-new-postdoc-position/" rel="alternate" type="text/html" title="New postdoc position" /><published>2017-09-20T00:00:00-04:00</published><updated>2017-09-20T00:00:00-04:00</updated><id>http://localhost:4000/milestones/new-postdoc-position</id><content type="html" xml:base="http://localhost:4000/milestones/2017-09-20-new-postdoc-position/">&lt;p&gt;We work on natural image segmentation. Our goal is to develop a neurally plausible model of image segmentation and to use it to conduct well control psychometric experiments with artificial and natural images.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@einstein.yu.edu</email></author><summary type="html">We work on natural image segmentation. Our goal is to develop a neurally plausible model of image segmentation and to use it to conduct well control psychometric experiments with artificial and natural images.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/einstein.jpg" /></entry><entry><title type="html">PhD Defense</title><link href="http://localhost:4000/milestones/2017-01-18-phd-defense/" rel="alternate" type="text/html" title="PhD Defense" /><published>2017-01-18T00:00:00-05:00</published><updated>2017-01-18T00:00:00-05:00</updated><id>http://localhost:4000/milestones/phd-defense</id><content type="html" xml:base="http://localhost:4000/milestones/2017-01-18-phd-defense/">&lt;p&gt;Finally a Doctor !&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;The goal of this thesis is to propose a mathematical model of visual stimulations in order to finely analyze experimental data in psychophysics and electrophysiology. More precisely, it is necessary to develop a set of dynamic, stochastic and parametric stimulations in order to exploit data analysis techniques from Bayesian statistics and machine learning. This problem is important to understand the visual system capacity to integrate and discriminate between stimuli. In particular, the measures performed at different scales (neurons, neural population, cognition) allow to study the particular sensitivities of neurons, their functional organization and their impact on decision making. To this purpose, we propose a set of theoretical, numerical and experimental contributions organized around three principal axes: (1) a Gaussian dynamic texture synthesis model specially crafted to probe vision; (2) a Bayesian observer model that accounts for the positive effect of spatial frequency over speed perception; (3) the use of machine learning techniques to analyze voltage sensitive dye optical imaging and extracellular data. This work, at the crossroads of neurosciences, psychophysics and mathematics is the fruit of several interdisciplinary collaborations.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@einstein.yu.edu</email></author><summary type="html">Finally a Doctor !</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/phd-words-cloud.png" /></entry><entry><title type="html">How to Apply a Filter Defined in the Frequency Domain by a Continuous Function ?</title><link href="http://localhost:4000/publications/2016-11-07-New-paper-in-IPOL/" rel="alternate" type="text/html" title="How to Apply a Filter Defined in the Frequency Domain by a Continuous Function ?" /><published>2016-11-07T00:00:00-05:00</published><updated>2016-11-07T00:00:00-05:00</updated><id>http://localhost:4000/publications/New-paper-in-IPOL</id><content type="html" xml:base="http://localhost:4000/publications/2016-11-07-New-paper-in-IPOL/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;
&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-Briand2016how&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;

&lt;p&gt;Mathematical details of discretization in Fourier domain.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column {
  float: left;
  width: 10%;
  padding: 5px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}
&lt;/style&gt;

&lt;span id=&quot;post2-Briand2016how&quot;&gt;Briand, T. &amp;amp; Vacher, J. How to Apply a Filter Defined in the Frequency Domain by a Continuous Function. &lt;i&gt;Image Processing On Line&lt;/i&gt; &lt;b&gt;6&lt;/b&gt;, 2016–11 (2016).&lt;/span&gt; &lt;br /&gt;

&lt;div class=&quot;row&quot;&gt;
	&lt;div class=&quot;column&quot;&gt;
		&lt;button onclick=&quot;myFunctionBriand2016how()&quot;&gt;&lt;img src=&quot;http://localhost:4000/assets/icons/BibTeX_logo.png&quot; /&gt;&lt;/button&gt; 
  	&lt;/div&gt;
  	&lt;div class=&quot;column&quot;&gt;
    		&lt;a href=&quot;/pdf/Briand2016how.pdf&quot;&gt;&lt;img src=&quot;http://localhost:4000/assets/icons/pdf_icon.png&quot; /&gt;&lt;/a&gt;
  	&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;Briand2016how-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;Briand2016how-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{Briand2016how,
  author = {Briand, Thibaud and Vacher, Jonathan},
  doi = {10.5201/ipol.2016.116},
  journal = {Image Processing On Line},
  keywords = {DFT,Fourier transform,convolution,filtering,interpolation,trigonometric polynomial},
  pages = {2016--11},
  title = {How to Apply a Filter Defined in the Frequency Domain by a Continuous Function},
  volume = {6},
  year = {2016}
}
&lt;/pre&gt;
&lt;/div&gt;


&lt;script&gt;
function myFunctionBriand2016how() {
  var x = document.getElementById(&quot;Briand2016how-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
&lt;/script&gt;

&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-Briand2016how&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;We propose algorithms for filtering real-valued images, when the filter is provided as a contin-uous function defined in the Nyquist frequency domain. This problem is ambiguous because images are discrete entities and there is no unique way to define the filtering. We provide a theoretical framework designed to analyse the classical and computationally efficient filtering implementations based on discrete Fourier transforms (DFT). In this framework, the filtering is interpreted as the convolution of a distribution, standing for the filter, with a trigonometric polynomial interpolator of the image. The various plausible interpolations and choices of the distribution lead to three equally licit algorithms which can be seen as method variants of the same standard filtering algorithm. In general none should be preferred to the others and the choice depends on the application. In practice, the method differences, which come from the boundary DFT coefficients, are not visible to the naked eye. We demonstrate that claim on several experimental configurations by varying the input image and the considered filter. In some cases however, we discuss how the choice of the variant may affect fundamental properties of the filtering. Source Code The source code and the online demo are accessible at the IPOL web part of this article 1. The C99 implementation of the code that we provide is the one which has been peer reviewed and accepted by IPOL. It contains two modules : one performs the standard filtering algorithm (Algorithm 1) presented in Section 3 and the other performs the comparison detailed in Section 4. The comparison module computes for nine filters the filtered images obtained by applying the three variant methods. For each filter a pairwise comparison of the results is done by computing the (absolute) difference image, the maximum difference and the mean difference. It creates fifty-five images: twenty-seven filtered images, twenty-seven difference images and the modulus of the DFT input in logarithmic scale. See Section 4 and the code documentation for additional information.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@einstein.yu.edu</email></author><summary type="html">Briand, T. &amp;amp; Vacher, J. How to Apply a Filter Defined in the Frequency Domain by a Continuous Function. Image Processing On Line 6, 2016–11 (2016). @article{Briand2016how, author = {Briand, Thibaud and Vacher, Jonathan}, doi = {10.5201/ipol.2016.116}, journal = {Image Processing On Line}, keywords = {DFT,Fourier transform,convolution,filtering,interpolation,trigonometric polynomial}, pages = {2016--11}, title = {How to Apply a Filter Defined in the Frequency Domain by a Continuous Function}, volume = {6}, year = {2016} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/discrete-ipol.png" /></entry><entry><title type="html">Biologically inspired dynamic textures for probing motion perception</title><link href="http://localhost:4000/publications/2015-12-07-New-paper-in-NIPS/" rel="alternate" type="text/html" title="Biologically inspired dynamic textures for probing motion perception" /><published>2015-12-07T00:00:00-05:00</published><updated>2015-12-07T00:00:00-05:00</updated><id>http://localhost:4000/publications/New-paper-in-NIPS</id><content type="html" xml:base="http://localhost:4000/publications/2015-12-07-New-paper-in-NIPS/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;
&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-Vacher2015biologically&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;

&lt;p&gt;Real-time dynamic texture synthesis for psychophysics and electrophysiology.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column {
  float: left;
  width: 10%;
  padding: 5px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}
&lt;/style&gt;

&lt;span id=&quot;post2-Vacher2015biologically&quot;&gt;Vacher, J., Meso, A. I., Perrinet, L. U. &amp;amp; Peyré, G. Biologically inspired dynamic textures for probing motion perception. in &lt;i&gt;Advances in Neural Information Processing Systems&lt;/i&gt; (2015).&lt;/span&gt; &lt;br /&gt;

&lt;div class=&quot;row&quot;&gt;
	&lt;div class=&quot;column&quot;&gt;
		&lt;button onclick=&quot;myFunctionVacher2015biologically()&quot;&gt;&lt;img src=&quot;http://localhost:4000/assets/icons/BibTeX_logo.png&quot; /&gt;&lt;/button&gt; 
  	&lt;/div&gt;
  	&lt;div class=&quot;column&quot;&gt;
    		&lt;a href=&quot;/pdf/Vacher2015biologically.pdf&quot;&gt;&lt;img src=&quot;http://localhost:4000/assets/icons/pdf_icon.png&quot; /&gt;&lt;/a&gt;
  	&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;Vacher2015biologically-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;Vacher2015biologically-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@inproceedings{Vacher2015biologically,
  author = {Vacher, Jonathan and Meso, Andrew Isaac and Perrinet, Laurent U. and Peyr{\'{e}}, Gabriel},
  booktitle = {Advances in Neural Information Processing Systems},
  issn = {10495258},
  title = {Biologically inspired dynamic textures for probing motion perception},
  year = {2015}
}
&lt;/pre&gt;
&lt;/div&gt;


&lt;script&gt;
function myFunctionVacher2015biologically() {
  var x = document.getElementById(&quot;Vacher2015biologically-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
&lt;/script&gt;

&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-Vacher2015biologically&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;Perception is often described as a predictive process based on an optimal inference with respect to a generative model. We study here the principled construction of a generative model specifically crafted to probe motion perception. In that context, we first provide an axiomatic, biologically-driven derivation of the model. This model synthesizes random dynamic textures which are defined by stationary Gaussian distributions obtained by the random aggregation of warped patterns. Importantly, we show that this model can equivalently be described as a stochastic partial differential equation. Using this characterization of motion in images, it allows us to recast motion-energy models into a principled Bayesian inference framework. Finally, we apply these textures in order to psychophysically probe speed perception in humans.In this framework, while the likelihood is derived from the generative model, the prior is estimated from the observed results and accounts for the perceptual bias in a principled fashion.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@einstein.yu.edu</email></author><summary type="html">Vacher, J., Meso, A. I., Perrinet, L. U. &amp;amp; Peyré, G. Biologically inspired dynamic textures for probing motion perception. in Advances in Neural Information Processing Systems (2015). @inproceedings{Vacher2015biologically, author = {Vacher, Jonathan and Meso, Andrew Isaac and Perrinet, Laurent U. and Peyr{\'{e}}, Gabriel}, booktitle = {Advances in Neural Information Processing Systems}, issn = {10495258}, title = {Biologically inspired dynamic textures for probing motion perception}, year = {2015} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/mc-nips.png" /></entry><entry><title type="html">The Heeger &amp;amp; Bergen Pyramid Based Texture Synthesis Algorithm</title><link href="http://localhost:4000/publications/2014-11-17-New-paper-in-IPOL/" rel="alternate" type="text/html" title="The Heeger &amp; Bergen Pyramid Based Texture Synthesis Algorithm" /><published>2014-11-17T00:00:00-05:00</published><updated>2014-11-17T00:00:00-05:00</updated><id>http://localhost:4000/publications/New-paper-in-IPOL</id><content type="html" xml:base="http://localhost:4000/publications/2014-11-17-New-paper-in-IPOL/">&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;
&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post1-Briand2014heeger&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;

&lt;p&gt;Reproduction of the Heeger-Bergen pyramid-based texture analysis/synthesis algorithm. Code in C and algorithmic details.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;style&gt;
* {
  box-sizing: border-box;
}

.column {
  float: left;
  width: 10%;
  padding: 5px;
}

/* Clearfix (clear floats) */
.row::after {
  content: &quot;&quot;;
  clear: both;
  display: table;
}
&lt;/style&gt;

&lt;span id=&quot;post2-Briand2014heeger&quot;&gt;Briand, T., Vacher, J., Galerne, B. &amp;amp; Rabin, J. The Heeger-Bergen Pyramid-Based Texture Synthesis Algorithm. &lt;i&gt;Image Processing On Line&lt;/i&gt; &lt;b&gt;4&lt;/b&gt;, 2014–11 (2014).&lt;/span&gt; &lt;br /&gt;

&lt;div class=&quot;row&quot;&gt;
	&lt;div class=&quot;column&quot;&gt;
		&lt;button onclick=&quot;myFunctionBriand2014heeger()&quot;&gt;&lt;img src=&quot;http://localhost:4000/assets/icons/BibTeX_logo.png&quot; /&gt;&lt;/button&gt; 
  	&lt;/div&gt;
  	&lt;div class=&quot;column&quot;&gt;
    		&lt;a href=&quot;/pdf/Briand2014heeger.pdf&quot;&gt;&lt;img src=&quot;http://localhost:4000/assets/icons/pdf_icon.png&quot; /&gt;&lt;/a&gt;
  	&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;Briand2014heeger-materials&quot; style=&quot;display:none&quot;&gt;
	&lt;pre id=&quot;Briand2014heeger-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{Briand2014heeger,
  author = {Briand, Thibaud and Vacher, Jonathan and Galerne, Bruno and Rabin, Julien},
  doi = {10.5201/ipol.2014.79},
  journal = {Image Processing On Line},
  keywords = {bergen,heeger,synthesis,texture},
  pages = {2014--11},
  title = {The Heeger-Bergen Pyramid-Based Texture Synthesis Algorithm},
  volume = {4},
  year = {2014}
}
&lt;/pre&gt;
&lt;/div&gt;


&lt;script&gt;
function myFunctionBriand2014heeger() {
  var x = document.getElementById(&quot;Briand2014heeger-materials&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
  } 
  else {
    x.style.display = &quot;none&quot;;
  }
}
&lt;/script&gt;

&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;!--&lt;a class=&quot;citation&quot; href=&quot;#post2-Briand2014heeger&quot;&gt;&lt;span style=&quot;vertical-align: super&quot;&gt;1&lt;/span&gt;&lt;/a&gt;--&gt;&lt;/h2&gt;

&lt;p&gt;This contribution deals with the Heeger-Bergen pyramid-based texture analysis/synthesis algorithm. It brings a detailed explanation of the original algorithm tested on many characteristic examples. Our analysis reproduces the original results, but also brings a minor improvement concerning non-periodic textures. Inspired by visual perception theories, Heeger and Bergen proposed to characterize a texture by its first-order statistics of both its color and its responses to multiscale and multi-orientation filters, namely the steerable pyramid. The Heeger-Bergen algorithm consists in the following procedure: starting from a white noise image, histogram matchings are performed to the image alternately in the image domain and the steerable pyramid domain, so that the corresponding output histograms match the ones of the input texture.&lt;/p&gt;</content><author><name>Jonathan Vacher</name><email>jonathan.vacher@einstein.yu.edu</email></author><summary type="html">Briand, T., Vacher, J., Galerne, B. &amp;amp; Rabin, J. The Heeger-Bergen Pyramid-Based Texture Synthesis Algorithm. Image Processing On Line 4, 2014–11 (2014). @article{Briand2014heeger, author = {Briand, Thibaud and Vacher, Jonathan and Galerne, Bruno and Rabin, Julien}, doi = {10.5201/ipol.2014.79}, journal = {Image Processing On Line}, keywords = {bergen,heeger,synthesis,texture}, pages = {2014--11}, title = {The Heeger-Bergen Pyramid-Based Texture Synthesis Algorithm}, volume = {4}, year = {2014} }</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/hb-tex.png" /></entry></feed>